{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from data.token_classification import TokenClassificationDataset\n",
    "from transformers import LayoutLMv3Tokenizer\n",
    "\n",
    "from src.modeling.docpolarbert.modeling_docpolarbert import DocPolarBERTForTokenClassification, DocPolarBERTModel\n",
    "from src.modeling.docpolarbert.train_utils import train_step_token_classification, eval_token_classification"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load PAYSLIPS dataset\n",
    "DATA_DIR = '../data/payslips'\n",
    "pad_token_label_id = CrossEntropyLoss().ignore_index\n",
    "SEED = 6\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 5e-5\n",
    "BATCH_SIZE = 16\n",
    "# Set all seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "tokenizer = LayoutLMv3Tokenizer.from_pretrained('microsoft/layoutlmv3-base')\n",
    "train_dataset = TokenClassificationDataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    tokenizer=tokenizer,\n",
    "    pad_token_label_id=pad_token_label_id,\n",
    "    mode='train')\n",
    "\n",
    "val_dataset = TokenClassificationDataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    tokenizer=tokenizer,\n",
    "    pad_token_label_id=pad_token_label_id,\n",
    "    mode='test')\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "\n",
    "train_sampler = torch.utils.data.RandomSampler(train_dataset, generator=g)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              sampler=train_sampler)\n",
    "\n",
    "val_sampler = torch.utils.data.RandomSampler(val_dataset, generator=g)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            sampler=val_sampler)\n",
    "\n"
   ],
   "id": "c5baa35f11542d11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DOCPOLARBERT_DIR = '../models/docpolarbert-base'\n",
    "\n",
    "model = DocPolarBERTForTokenClassification.from_pretrained(DOCPOLARBERT_DIR, num_labels=len(train_dataset.idx2label))\n",
    "model.to(\"cpu\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    avg_eval_loss, precision, recall, f1 = eval_token_classification(\n",
    "    model=model,\n",
    "    eval_dataloader=val_dataloader,\n",
    "    idx2label=val_dataset.idx2label,\n",
    "    print_results=True)\n",
    "    print(f\"Epoch [{0}/{NUM_EPOCHS}], Average validation loss: {avg_eval_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}.\")\n"
   ],
   "id": "10c7564f5d566bdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_epoch = time.time()\n",
    "    print(f'Starting epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "    avg_loss  = train_step_token_classification(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            idx2label=train_dataset.idx2label,\n",
    "            optimizer=optimizer,\n",
    "            )\n",
    "    # ---------------------------------------- Validation ---------------------------------------- #\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        avg_eval_loss, precision, recall, f1 = eval_token_classification(\n",
    "            model=model,\n",
    "            eval_dataloader=val_dataloader,\n",
    "            idx2label=val_dataset.idx2label,\n",
    "            print_results=True)\n",
    "        print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}], Average training loss: {avg_loss:.4f}, Average validation loss: {avg_eval_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}.\")\n",
    "        print(f\"Time taken for epoch {epoch + 1}: {datetime.timedelta(seconds=int(time.time() - start_epoch))}\")\n",
    "    model.train()"
   ],
   "id": "a9248466235605f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run evaluation on the validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    avg_eval_loss, precision, recall, f1 = eval_token_classification(\n",
    "        model=model,\n",
    "        eval_dataloader=val_dataloader,\n",
    "        idx2label=val_dataset.idx2label,\n",
    "        print_results=True)\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}.\")"
   ],
   "id": "1018875732849aff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.config.id2label = val_dataset.idx2label\n",
    "model.config.label2id = val_dataset.label2idx\n",
    "# Save fine-tuned model\n",
    "model.save_pretrained('models/docpolarbert-payslips')"
   ],
   "id": "a54fd0d9a910ec74",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
